#!/usr/bin/env python3
"""
æ·±åº¦æœç´¢åˆ†ææ¨¡å— - çœŸå®éœ€æ±‚æŒ–æ˜
æœç´¢ Redditã€è®ºå›ã€Google æ‰¾çœŸå®ç”¨æˆ·ç—›ç‚¹å’Œéœ€æ±‚
"""

import asyncio
import aiohttp
import logging
from typing import Dict, List
from urllib.parse import quote_plus

logger = logging.getLogger(__name__)


class DeepSearchAnalyzer:
    """æ·±åº¦æœç´¢åˆ†æå™¨ - æŒ–æ˜çœŸå®ç”¨æˆ·éœ€æ±‚"""
    
    def __init__(self):
        # Reddit å­ç‰ˆå—ï¼ˆå·¥å…·ç±»éœ€æ±‚é›†ä¸­åœ°ï¼‰
        self.reddit_subs = [
            "r/webdev", "r/programming", "r/learnprogramming",
            "r/software", "r/technology", "r/python", "r/javascript",
            "r/entrepreneur", "r/smallbusiness", "r/productivity",
            "r/SEO", "r/marketing", "r/growthhacking"
        ]
        
        # è®ºå›åˆ—è¡¨
        self.forums = [
            "stackoverflow.com", "producthunt.com", " hackernews.com",
            "reddit.com", "quora.com", "www.reddit.com/r/webdev",
            "www.reddit.com/r/programming"
        ]
        
        # ç—›ç‚¹æœç´¢å…³é”®è¯
        self.pain_keywords = [
            "struggling with", "how to fix", "error", "problem",
            "cannot", "doesn't work", "failed", "help me",
            "annoying", "tedious", "time consuming", "frustrated",
            "wish there was", "looking for", "need a tool"
        ]
    
    async def search_reddit(self, keyword: str) -> Dict:
        """æœç´¢ Reddit è®¨è®º"""
        results = {
            "reddit_posts": [],
            "reddit_comments": [],
            "pain_points_found": []
        }
        
        try:
            # æœç´¢ Reddit (ä½¿ç”¨ Google æœç´¢ç»“æœ)
            search_url = f"https://www.google.com/search?q={quote_plus(keyword)}+site:reddit.com"
            
            # è¿™é‡Œå¯ä»¥ç”¨ Playwright è·å–çœŸå®æœç´¢ç»“æœ
            results["search_url"] = search_url
            
            # æ¨¡æ‹Ÿï¼šè®°å½•æœç´¢æ„å›¾
            for pain in self.pain_keywords:
                if pain in keyword.lower():
                    results["pain_points_found"].append(pain)
                    
        except Exception as e:
            logger.error(f"Reddit search error for '{keyword}': {e}")
        
        return results
    
    async def search_forums(self, keyword: str) -> Dict:
        """æœç´¢æŠ€æœ¯è®ºå›"""
        results = {
            "forum_discussions": [],
            "stackoverflow_questions": [],
            "real_needs": []
        }
        
        try:
            # Stack Overflow æœç´¢
            so_url = f"https://stackoverflow.com/search?q={quote_plus(keyword)}"
            results["stackoverflow_url"] = so_url
            
            # æ£€æµ‹æ˜¯å¦æ˜¯æŠ€æœ¯å·¥å…·éœ€æ±‚
            tech_keywords = ["converter", "generator", "calculator", "parser", "formatter"]
            if any(tk in keyword.lower() for tk in tech_keywords):
                results["real_needs"].append("æŠ€æœ¯å·¥å…·éœ€æ±‚ - Stack Overflow é«˜é¢‘")
            
            # æ£€æµ‹æ¯”è¾ƒéœ€æ±‚
            compare_keywords = ["vs", "alternative", "better"]
            if any(cp in keyword.lower() for cp in compare_keywords):
                results["real_needs"].append("å¯¹æ¯”/æ›¿ä»£éœ€æ±‚ - ç”¨æˆ·æƒ³æ‰¾æ›´å¥½çš„æ–¹æ¡ˆ")
                
        except Exception as e:
            logger.error(f"Forum search error for '{keyword}': {e}")
        
        return results
    
    async def analyze_google_trends(self, keyword: str) -> Dict:
        """åˆ†æ Google æœç´¢è¶‹åŠ¿"""
        results = {
            "trend_direction": "stable",
            "related_queries": [],
            "question_queries": []
        }
        
        try:
            # Google ç›¸å…³æœç´¢
            related_url = f"https://www.google.com/search?q={quote_plus(keyword)}&related=1"
            results["related_url"] = related_url
            
            # é—®ç­”å‹æŸ¥è¯¢
            question_words = ["how", "what", "why", "where", "when"]
            if any(qw in keyword.lower() for qw in question_words):
                results["question_queries"].append("ç”¨æˆ·æƒ³å­¦ä¹ /ç†è§£")
            
            # å·¥å…·å‹æŸ¥è¯¢
            tool_words = ["tool", "generator", "maker", "creator"]
            if any(tw in keyword.lower() for tw in tool_words):
                results["question_queries"].append("ç”¨æˆ·åœ¨æ‰¾å·¥å…·")
                
        except Exception as e:
            logger.error(f"Google trends error for '{keyword}': {e}")
        
        return results
    
    async def analyze_keyword(self, keyword: str) -> Dict:
        """ç»¼åˆæ·±åº¦åˆ†æå•ä¸ªå…³é”®è¯"""
        logger.info(f"   ğŸ” æ·±åº¦åˆ†æ: {keyword}")
        
        # å¹¶è¡Œæœç´¢
        reddit, forums, trends = await asyncio.gather(
            self.search_reddit(keyword),
            self.search_forums(keyword),
            self.analyze_google_trends(keyword)
        )
        
        # åˆå¹¶ç»“æœ
        analysis = {
            "keyword": keyword,
            "reddit": reddit,
            "forums": forums,
            "trends": trends,
            "demand_strength": self._calc_demand_strength(reddit, forums, trends),
            "community_buzz": len(reddit.get("pain_points_found", [])),
            "is_tool_demand": "tool" in keyword.lower(),
            "is_pain_point": len(reddit.get("pain_points_found", [])) > 0,
            "is_comparison": "vs" in keyword.lower() or "alternative" in keyword.lower()
        }
        
        return analysis
    
    def _calc_demand_strength(self, reddit: Dict, forums: Dict, trends: Dict) -> str:
        """è®¡ç®—éœ€æ±‚å¼ºåº¦"""
        score = 0
        
        if reddit.get("pain_points_found"):
            score += 3  # ç—›ç‚¹éœ€æ±‚
        
        if forums.get("real_needs"):
            score += 2  # çœŸå®éœ€æ±‚
        
        if trends.get("question_queries"):
            score += 2  # ä¸»åŠ¨æœç´¢
        
        if score >= 5:
            return "HIGH"
        elif score >= 3:
            return "MEDIUM"
        else:
            return "LOW"
    
    async def analyze_batch(self, keywords: List[str]) -> Dict[str, Dict]:
        """æ‰¹é‡æ·±åº¦åˆ†æ"""
        results = {}
        
        logger.info(f"ğŸ¯ å¼€å§‹æ·±åº¦åˆ†æ {len(keywords)} ä¸ªå…³é”®è¯...")
        
        for keyword in keywords:
            try:
                analysis = await self.analyze_keyword(keyword)
                results[keyword] = analysis
                
                # ç®€çŸ­æ—¥å¿—
                demand = analysis["demand_strength"]
                pain = "âš ï¸" if analysis["is_pain_point"] else ""
                logger.info(f"   â†’ {keyword}: {demand} éœ€æ±‚ {pain}")
                
            except Exception as e:
                logger.error(f"åˆ†æå¤±è´¥ '{keyword}': {e}")
                results[keyword] = {"keyword": keyword, "error": str(e)}
        
        logger.info(f"âœ… å®Œæˆ {len(results)} ä¸ªå…³é”®è¯æ·±åº¦åˆ†æ")
        return results


# ä¾¿æ·å‡½æ•°
async def deep_search(keywords: List[str]) -> Dict[str, Dict]:
    """æ‰§è¡Œæ·±åº¦æœç´¢"""
    analyzer = DeepSearchAnalyzer()
    return await analyzer.analyze_batch(keywords)


if __name__ == "__main__":
    # æµ‹è¯•
    test_keywords = [
        "free image converter",
        "python json formatter",
        "website seo checker",
        "logo maker free",
        "password generator"
    ]
    
    results = asyncio.run(deep_search(test_keywords))
    
    for kw, data in results.items():
        print(f"\n{kw}:")
        print(f"   éœ€æ±‚å¼ºåº¦: {data.get('demand_strength', 'N/A')}")
        print(f"   ç—›ç‚¹: {data.get('is_pain_point')}")
        print(f"   å·¥å…·éœ€æ±‚: {data.get('is_tool_demand')}")
