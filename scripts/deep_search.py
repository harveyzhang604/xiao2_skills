#!/usr/bin/env python3
"""
æ·±åº¦æœç´¢åˆ†æå™¨ V4 - éœ€æ±‚çœŸä¼ªéªŒè¯ + å•†ä¸šä»·å€¼åˆ¤æ–­
====================================================

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. 5é—®æ³•éªŒè¯éœ€æ±‚çœŸä¼ª
2. Reddit ç—›ç‚¹æŒ–æ˜
3. ç«äº‰åŸŸååˆ†æ
4. çœŸå®æœç´¢æ„å›¾åˆ¤æ–­
"""

import asyncio
import aiohttp
import re
import requests
import logging
from typing import Dict, List
from urllib.parse import quote_plus

logger = logging.getLogger(__name__)


class DeepSearchAnalyzerV4:
    """æ·±åº¦æœç´¢åˆ†æå™¨ V4 - éœ€æ±‚éªŒè¯ç‰ˆ"""
    
    def __init__(self):
        # ç—›ç‚¹ä¿¡å·è¯
        self.pain_keywords = PAIN_TRIGGERS['critical'] + PAIN_TRIGGERS['medium']
        
        # éœ€æ±‚ä¿¡å·è¯
        self.demand_signals = TRANSACTIONAL_SIGNALS
    
    def validate_demand_5_questions(self, keyword: str, 
                                     reddit_data: Dict = None,
                                     google_data: Dict = None) -> Dict:
        """
        5é—®æ³•éªŒè¯éœ€æ±‚çœŸä¼ª
        
        Q1: æ˜¯ Info è¿˜æ˜¯ Transactional æ„å›¾?
        Q2: æ˜¯å¦æœ‰å·¥å…·/è§£å†³æ–¹æ¡ˆ?
        Q3: ç”¨æˆ·æ˜¯å¦åœ¨æŠ±æ€¨?
        Q4: æ˜¯å¦æœ‰ä»˜è´¹æ„æ„¿?
        Q5: ç«äº‰æ˜¯å¦æ¿€çƒˆ?
        """
        keyword_lower = keyword.lower()
        
        answers = {}
        score = 0
        
        # Q1: æ„å›¾ç±»å‹
        is_transactional = False
        for signal in self.demand_signals['tool']:
            if signal in keyword_lower:
                is_transactional = True
                answers['Q1'] = f"Transactional (å·¥å…·éœ€æ±‚): {signal}"
                score += 20
                break
        
        if not is_transactional:
            for signal in INFO_SIGNALS:
                if signal in keyword_lower:
                    answers['Q1'] = f"Info (ä¿¡æ¯éœ€æ±‚): {signal}"
                    score -= 10
                    break
            else:
                answers['Q1'] = "Mixed (æ··åˆ)"
        
        # Q2: è§£å†³æ–¹æ¡ˆæ£€æµ‹
        has_solution = False
        for signal in ['tool', 'app', 'software', 'generator', 'online']:
            if signal in keyword_lower:
                has_solution = True
                answers['Q2'] = f"æœ‰æ˜ç¡®è§£å†³æ–¹æ¡ˆä¿¡å·: {signal}"
                score += 10
                break
        
        if not has_solution:
            answers['Q2'] = "æ— æ˜ç¡®è§£å†³æ–¹æ¡ˆä¿¡å·"
        
        # Q3: ç—›ç‚¹æ£€æµ‹
        pain_count = 0
        found_pains = []
        for pain in self.pain_keywords:
            if pain in keyword_lower:
                found_pains.append(pain)
                pain_count += 1
        
        if pain_count > 0:
            answers['Q3'] = f"ç—›ç‚¹å‘ç°: {', '.join(found_pains)}"
            score += pain_count * 15
        else:
            answers['Q3'] = "æœªå‘ç°æ˜æ˜¾ç—›ç‚¹"
        
        # Q4: ä»˜è´¹æ„æ„¿ (é€šè¿‡ Reddit åˆ†æ)
        if reddit_data:
            comments = reddit_data.get('total_mentions', 0)
            if comments > 5:
                answers['Q4'] = f"Redditè®¨è®ºæ´»è·ƒ ({comments}æ¡), å¯èƒ½å­˜åœ¨ä»˜è´¹éœ€æ±‚"
                score += 15
            elif comments > 0:
                answers['Q4'] = f"å°‘é‡Redditè®¨è®º ({comments}æ¡)"
                score += 5
            else:
                answers['Q4'] = "Redditæ— æ´»è·ƒè®¨è®º"
        else:
            answers['Q4'] = "æ— Redditæ•°æ®"
        
        # Q5: ç«äº‰åˆ†æ
        if google_data:
            competitors = google_data.get('competitors', [])
            has_giant = any(c in GIANTS for c in competitors)
            has_weak = any(c in WEAK_COMPETITORS for c in competitors)
            
            if has_giant:
                answers['Q5'] = f"å·¨å¤´å­˜åœ¨: {competitors[:2]}"
                score -= 20
            elif has_weak:
                answers['Q5'] = f"å¼±ç«äº‰ (æœºä¼š): {competitors[:2]}"
                score += 25
            else:
                answers['Q5'] = f"ä¸­ç­‰ç«äº‰: {competitors[:2] if competitors else 'æœªçŸ¥'}"
        else:
            answers['Q5'] = "æ— ç«äº‰æ•°æ®"
        
        # æœ€ç»ˆéªŒè¯ç»“æœ
        is_valid = score >= 60 and (is_transactional or pain_count > 0)
        
        return {
            'is_valid': is_valid,
            'score': min(100, max(0, score)),
            'intent_type': 'transactional' if is_transactional else 'info',
            'questions': answers,
            'pain_count': pain_count,
            'found_pains': found_pains
        }
    
    def search_reddit_real(self, keyword: str) -> Dict:
        """çœŸå®æœç´¢ Reddit ç—›ç‚¹è®¨è®º"""
        results = {
            'total_mentions': 0,
            'pain_posts': [],
            'sentiment': 'neutral',
            'solution_seeking': 0
        }
        
        try:
            url = f"https://www.reddit.com/search.json?q={quote_plus(keyword)}&limit=20&sort=relevance"
            headers = {"User-Agent": "Mozilla/5.0"}
            
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            data = response.json()
            
            posts = data.get("data", {}).get("children", [])
            results['total_mentions'] = len(posts)
            
            pain_posts = []
            solution_seeking = 0
            
            for post in posts:
                post_data = post.get("data", {})
                title = post_data.get("title", "").lower()
                selftext = post_data.get("selftext", "").lower()
                combined = title + " " + selftext
                
                # ç—›ç‚¹æ£€æµ‹
                for pain in self.pain_keywords:
                    if pain in combined:
                        pain_posts.append({
                            'title': post_data.get("title", ""),
                            'score': post_data.get("score", 0),
                            'comments': post_data.get("num_comments", 0)
                        })
                        break
                
                # è§£å†³æ–¹æ¡ˆå¯»æ±‚
                for signal in ['looking for', 'need a tool', 'is there a', 'wish there was']:
                    if signal in combined:
                        solution_seeking += 1
                        break
            
            results['pain_posts'] = pain_posts[:5]
            results['solution_seeking'] = solution_seeking
            
            # æƒ…æ„Ÿåˆ†æ
            if len(pain_posts) > 3:
                results['sentiment'] = 'negative'  # å¤§é‡ç—›ç‚¹
            elif solution_seeking > 2:
                results['sentiment'] = 'seeking'  # å¯»æ±‚è§£å†³æ–¹æ¡ˆ
            
        except Exception as e:
            logger.debug(f"Reddit search error for '{keyword}': {e}")
        
        return results
    
    def analyze_google_serp(self, keyword: str) -> Dict:
        """åˆ†æ Google SERP ç«äº‰ç¯å¢ƒ"""
        results = {
            'competitors': [],
            'has_giant': False,
            'has_weak': False,
            'commercial_intent': 0
        }
        
        try:
            url = f"https://www.google.com/search?q={quote_plus(keyword)}&num=10"
            headers = {"User-Agent": "Mozilla/5.0"}
            
            response = requests.get(url, headers=headers, timeout=15)
            html = response.text
            
            # æå–åŸŸå
            domains = re.findall(r'https?://([^/]+)', html)
            unique_domains = []
            for d in domains:
                d = d.replace('www.', '')
                if d not in unique_domains and len(d) < 50:
                    unique_domains.append(d)
            
            results['competitors'] = unique_domains[:5]
            
            # æ£€æµ‹å·¨å¤´
            for domain in unique_domains:
                if any(g in domain for g in GIANTS):
                    results['has_giant'] = True
                    break
            
            # æ£€æµ‹å¼±ç«äº‰è€…
            for domain in unique_domains:
                if any(w in domain for w in WEAK_COMPETITORS):
                    results['has_weak'] = True
                    break
            
            # å•†ä¸šæ„å›¾
            tool_count = sum(1 for d in unique_domains for t in ['tool', 'app', 'software'] if t in d)
            results['commercial_intent'] = min(100, tool_count * 20)
            
        except Exception as e:
            logger.debug(f"Google SERP error for '{keyword}': {e}")
        
        return results
    
    def analyze_keyword(self, keyword: str) -> Dict:
        """ç»¼åˆæ·±åº¦åˆ†æ"""
        logger.info(f"   ğŸ” æ·±åº¦åˆ†æ: {keyword}")
        
        # è·å–æ•°æ®
        reddit = self.search_reddit_real(keyword)
        google = self.analyze_google_serp(keyword)
        
        # 5é—®æ³•éªŒè¯
        validation = self.validate_demand_5_questions(keyword, reddit, google)
        
        # å•†ä¸šä»·å€¼åˆ¤æ–­
        monetization_score = self._calc_monetization(keyword)
        
        # ç—›ç‚¹åˆ†æ•°
        pain_score = self._calc_pain(keyword, reddit)
        
        return {
            'keyword': keyword,
            'validation': validation,
            'reddit': reddit,
            'google': google,
            'monetization_score': monetization_score,
            'pain_score': pain_score,
            'demand_strength': self._calc_demand_strength(validation, reddit, google),
            'is_valid_transactional': validation['intent_type'] == 'transactional' and validation['is_valid'],
            'is_pain_point': validation['pain_count'] > 0
        }
    
    def _calc_monetization(self, keyword: str) -> Dict:
        """è®¡ç®—å•†ä¸šä»·å€¼"""
        score = 50
        signals = []
        keyword_lower = keyword.lower()
        
        # B2B
        for signal in TRANSACTIONAL_SIGNALS['b2b']:
            if signal in keyword_lower:
                signals.append(f"B2B: {signal}")
                score += 20
                break
        
        # Transactional
        for signal in TRANSACTIONAL_SIGNALS['tool']:
            if signal in keyword_lower:
                signals.append(f"å·¥å…·: {signal}")
                score += 15
                break
        
        # å…è´¹
        if 'free' in keyword_lower:
            signals.append("å…è´¹")
            score += 5
        
        return {'score': min(100, score), 'signals': signals}
    
    def _calc_pain(self, keyword: str, reddit: Dict) -> Dict:
        """è®¡ç®—ç—›ç‚¹åˆ†æ•°"""
        score = 50
        keyword_lower = keyword.lower()
        keywords = []
        level = 'low'
        
        for pain in self.pain_keywords:
            if pain in keyword_lower:
                keywords.append(pain)
                score += 15
                level = 'critical' if 'struggling' in pain or 'fix' in pain else 'medium'
        
        if reddit.get('solution_seeking', 0) > 0:
            score += 10
            level = 'critical'
        
        return {'score': min(100, score), 'level': level, 'keywords': keywords[:3]}
    
    def _calc_demand_strength(self, validation: Dict, reddit: Dict, google: Dict) -> str:
        """è®¡ç®—éœ€æ±‚å¼ºåº¦"""
        score = validation['score']
        
        if reddit.get('total_mentions', 0) > 5:
            score += 20
        elif reddit.get('total_mentions', 0) > 0:
            score += 10
        
        if google.get('has_weak') and not google.get('has_giant'):
            score += 25
        
        if score >= 80:
            return 'HIGH'
        elif score >= 50:
            return 'MEDIUM'
        else:
            return 'LOW'
    
    def analyze_batch(self, keywords: List[str]) -> Dict[str, Dict]:
        """æ‰¹é‡æ·±åº¦åˆ†æ"""
        results = {}
        
        logger.info(f"ğŸ¯ å¼€å§‹æ·±åº¦åˆ†æ {len(keywords)} ä¸ªå…³é”®è¯...")
        
        for i, keyword in enumerate(keywords, 1):
            try:
                analysis = self.analyze_keyword(keyword)
                results[keyword] = analysis
                
                status = "âœ…" if analysis['is_valid_transactional'] else "âš ï¸"
                demand = analysis['demand_strength']
                logger.info(f"   {i}/{len(keywords)} {keyword}: {demand} {status}")
                
            except Exception as e:
                logger.error(f"åˆ†æå¤±è´¥ '{keyword}': {e}")
                results[keyword] = {"keyword": keyword, "error": str(e)}
        
        logger.info(f"âœ… å®Œæˆ {len(results)} ä¸ªå…³é”®è¯æ·±åº¦åˆ†æ")
        return results


# ä¾¿æ·å‡½æ•°
def deep_search(keywords: List[str]) -> Dict[str, Dict]:
    """æ‰§è¡Œæ·±åº¦æœç´¢"""
    analyzer = DeepSearchAnalyzerV4()
    return analyzer.analyze_batch(keywords)
